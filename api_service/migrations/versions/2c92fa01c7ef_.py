"""empty message

Revision ID: 2c92fa01c7ef
Revises: 7d4c7414c89e
Create Date: 2019-05-16 12:39:40.321616

"""
import hashlib
import os
from datetime import datetime
from glob import glob

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
from sqlalchemy import Column, String, DateTime
from sqlalchemy.orm import sessionmaker

from seattle_flu_incidence_mapper.orm_config import get_declarative_base

connection = op.get_bind()
Session = sessionmaker()


revision = '2c92fa01c7ef'
down_revision = '7d4c7414c89e'
branch_labels = None
depends_on = None


old_model_name = 'pathogen_model'
new_model_name = 'generic_model'


class PathogenModel(get_declarative_base()):
    __tablename__ = 'pathogen_model'
    id = Column(String,  primary_key=True)
    name = Column(String)
    query_str = Column(String)
    model_type = Column(String)
    rds_key = Column(String)
    model_key = Column(String)
    created = Column(DateTime, primary_key=True, default=datetime.utcnow)


def upgrade():
    delete_old_models()
    # ### commands auto generated by Alembic - please adjust! ###
    # sqlite doesn't support drop constraint so
    # create our new table
    op.create_table(new_model_name,
                    sa.Column('id', sa.VARCHAR(), nullable=False, primary_key=True),
                    sa.Column('name', sa.VARCHAR(), nullable=True),
                    sa.Column('query_str', sa.VARCHAR(), nullable=True),
                    sa.Column('model_type', sa.VARCHAR(), nullable=True),
                    sa.Column('rds_key', sa.VARCHAR(), nullable=True),
                    sa.Column('model_key', sa.VARCHAR(), nullable=False, primary_key=True),
                    sa.Column('created', sa.DATETIME(), nullable=False),
                    sa.PrimaryKeyConstraint('id', 'model_key')
                    )

    # add our column to our old table and populate the column
    with op.batch_alter_table(old_model_name) as batch_op:
        batch_op.add_column(Column('model_key', String()))
    populate_model_keys()

    old_columns =  ['id', 'name', 'query_str', 'model_type', 'rds_key', 'model_key', 'created']
    col_str = ",".join(old_columns)
    op.execute(f'INSERT INTO {new_model_name} ({col_str}) SELECT {col_str} FROM {old_model_name};')
    op.drop_table(old_model_name)
     ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.rename_table(new_model_name, old_model_name)
    with op.batch_alter_table(old_model_name) as batch_op:
        batch_op.drop_column('model_key')
    # ### end Alembic commands ###


def delete_old_models():
    # cleanup defunc models?
    session = Session(bind=connection)
    from flask import current_app
    base_path = current_app.config.get('MODEL_STORE', '/model_store')
    model_ids = list(session.query(PathogenModel.id).distinct())
    model_ids = set([r for r, in model_ids])
    for file in glob(f"{base_path}/*.csv"):
        if os.path.basename(file)[:-4] not in model_ids:
            print(f'Removing old model {file}')
            os.remove(file)
    session.commit()


def populate_model_keys():
    session = Session(bind=connection)
    from seattle_flu_incidence_mapper.model_store import get_model_file
    model_id_key_hash = {}
    # let's calculate our model keys and rds keys
    for model in session.query(PathogenModel).order_by(PathogenModel.created.desc()).all():
        modelfile = get_model_file(model.id)
        with open(modelfile, 'r') as mf:
            model_key = hashlib.md5(mf.read().encode('utf-8')).hexdigest()
            model.model_key = model_key
        combo_id = model.id + model_key
        if combo_id not in model_id_key_hash:
            model_id_key_hash[model.id + model_key] = True
            session.add(model)
        else:
            session.delete(model)

    # now find models that have duplicate ids/model keys
    # only keep the latest
    session.flush()
    session.commit()